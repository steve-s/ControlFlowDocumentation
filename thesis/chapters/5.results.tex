%pygmentize_options: -O startinline=True
\chapter{Results}
\label{results}
We evaluated Control Flow for Phalanger on several open source PHP projects. 
In order to have a comparison to another established tool of similar type, 
we analysed one of the PHP projects with both Control Flow for Phalanger and 
Phantm. The discussion of the differences in results is provided in the 
following section. The rest of the PHP projects were analysed only with 
Control Flow for Phalanger and the reported problems were manually inspected 
and categorized. Moreover, we measured execution time and memory 
consumption of the analysis with several PHP projects of 
different sizes to investigate its scalability.


\section{Comparison to Phantm\label{phantmresults}}

The project we chose for comparison evaluation is Zebra\_Image \cite{zebraimage}. 
It is a PHP image manipulation library that consists of 1707 lines of code 
in one file and one class. Zebra\_Image code contains some type documentation, 
but incomplete and often written in a way that does not follow the standard 
PHPDoc type description grammar.

All the problems reported by either tool were briefly inspected and 
categorized. The results are presented in the following table and 
are very different for each tool, which can be due to the 
different approaches to the analysis. The actual problems reported and 
the possible reasons for the difference in results are discussed in 
the following paragraphs.

\begin{center}
    \begin{tabular}{| p{6cm} | r | r |}
    \hline
    \textbf{Category}           &   \textbf{Phantm}      &   \textbf{Control Flow for Phalanger} \\ \hline
    All Reported problems       &     130                &    1   \\ \hline
    Uninitialized variable use  &       2                &    1   \\ \hline
    Zebra\_Image dynamic fields  &       82               &    0     \\ \hline
    Any is not of type X        &       13               &    0     \\ \hline    
    Prototype errors            &       9                &    0     \\ \hline    
    Conversion: double to integer&       2               &    0     \\ \hline    
    Other type conversions      &       2               &    0     \\ \hline    
    Not categorized             &       17               &    0     \\ \hline    
    \end{tabular}
\end{center}

\subsubsection*{Reported Problems}

The uninitialized variable error appears to be genuine problem that would 
generate a notice at runtime. It was discovered by both tools. Because the 
variable in question is accessed as an array using the \code{[]} operator, 
Phantm reported it twice, because it treats it as two variable accesses.

All the prototype errors are false positives probably due to the fact 
that Phantm does not distinguish mandatory and optional parameters. 
In PHP, any routine can take any number of arguments. Arguments explicitly 
named in the signature are mandatory, but any number of optional arguments can be 
accessed using intrinsic functions. Therefore it is not necessarily a prototype 
error if a routine is given more parameters than the number of 
parameters explicitly named in its signature.

PHP allows to use undeclared object fields, they are dynamically created when 
first used, usually assigned to. Zebra\_Image relies on this and dynamically 
creates some fields in certain methods and then uses them in 
other methods, which is reported by Phantm. Using fields without 
explicitly declaring them can be seen as a style error, especially in case 
of Zebra\_Image, because all the fields in question are in fact known 
beforehand and therefore it is perfectly possible to explicitly declare them. 
In other cases, however, this language feature enables useful patterns 
mainly in combination with magic \code{\_\_set} and \code{\_\_get} methods, as 
for example in model classes of Doctrine Object-Relational Mapper \cite{doctrine}.

Phantm regards some implicit type conversions as errors. Namely anything to 
string type conversion, which is typically used in PHP, and double to 
integer, which is more debatable, but nonetheless often used deliberately 
instead of cast or floor or ceiling functions.

\subsubsection*{Conclusion}

Those results can indicate that, although at first sight the aims of the
two tools are the same, under closer inspection, they differ. 
Phantm attempts to more precise analysis. For example, 
by modelling heap memory. Such precision is, in theory, more powerful 
and can discover more actual problems; yet, it also yields
many false positives. It would be possible to filter out the 
``likely to be'' false positives, but that would filter out those 
cases where due to the better precision, Phantm discovered 
actual error.

On the other hand, although being less precise, Control Flow for 
Phalanger seems to have better ratio of false positives. 
This could make it more suitable option for a day to day development, 
which is what it is focused on. 

Because of this difference, the results for other PHP projects were 
manually inspected only in the case of Control Flow for Phalanger.


\section{Evaluation on open source PHP code}

For further evaluation, the following open source PHP frameworks were chosen:

\begin{description}
    \item[PHPUnit:] a port of JUnit unit testing framework for PHP; it is a mature 
    and well established project that has been developed for more than 6 years 
    by 156 contributors. Being a unit testing framework, PHPUnit itself has extensive 
    unit test suite. For the experiment the master branch of the clone of the 
    repository retrieved on 18.5.2014 has been used. 
    
    \item[Nette:] popular general purpose PHP framework with long development 
    history and contributions from 137 developers. Nette has unit test suite 
    with good code coverage and the source code is very well documented including 
    the type documentation comments.
\end{description}

    \begin{comment}
    \item[Zend Framework:] popular general purpose PHP framework. Lorem ipsum...
        \note{over 3000 problems reported. Quite a big bite to chew with analysing and categorizing all of them.}        
        
    \item[Piwik:] open source version of Google Analytics. \note{few hundred problems found, not categorized yet}
    
    \item[PrestaShop:] open source e-commerce solution. \note{few hundred problems found, not categorized yet}
    
    \item[Composer:] popular dependency management system for PHP libraries. \note{few hundred problems found, not categorized yet}
    \end{comment}

An evaluation always started with downloading a git repository with the 
latest source code of given PHP project. Then the analysis was run and 
all the discovered problems were collected and categorized.
Actual errors were rectified and recorded as commits in the 
git repository. 

Often one real issue in the source code caused several 
warnings to be reported by the tool. For instance, if a documentation 
of a type of a field was not correct, most of the lines where 
a value was assigned to that field were reported, however, the 
root of the cause was actually the only one line with the 
wrong type documentation. Such cases were counted as a 
single problem.

\subsection{Problems Taxonomy}

The problems were divided into few main categories 
described below.

\paragraph*{Style:} a category of problems that 
are not directly affecting the functionality of the 
application, but they can be considered as a bad 
coding style. 

\begin{itemize}
    \item[] \textit{Relaying on default return value} -- when an execution of a 
        routine does not end with a return statement, its 
        return value is \code{NULL} by default, which can then 
        be cast to values of other types, like \code{false} 
        for example. Developers rely on this feature and omit 
        the return statement if they want to return \code{NULL} or 
        something that \code{NULL} can be cast to.
\end{itemize}

\paragraph*{Documentation:} inconsistency of the PHPDoc type 
documentation with what the actual code does. This category includes 
only cases where it is clear that the documentation is wrong, 
for example, due to updates in the code that were not reflected 
in the documentation. The inconsistency may also indicate 
another problem, in which case it does not belong to this category. 

Interestingly, most of the inconsistencies of type of a parameter 
of a function call typically lead through several routines that 
only forward the parameter to the next routine until 
eventually the routine that has a wrong documentation is reached.

\begin{itemize}
    \item[] \textit{Missing} \code{false} \textit{in return value type documentation} -- 
        this is common pattern in PHP where a routine returns \code{false} 
        when it fails to do what it was supposed to do. For example, 
        function \code{fopen} returns \code{resource} of \code{false} 
        if the resource could not be opened. It is so common that 
        developers tend to forget to put \code{false} into the documentation.
\end{itemize}

\paragraph*{Actual Error:} includes all problems that can cause 
an unexpected exception or unexpected runtime error or notice.


\paragraph*{False Positive:} problems reported by the tool that 
are not in fact real problems. 

\begin{itemize}
    \item[] \textit{Unused routine arguments} -- when a method is an override of 
        some base method, it can have the same signature and if some of the 
        parameters are not used, they are not reported. There are however 
        some cases where the routine is implementing some interface by convention 
        that is not explicitly expressed in the syntax of PHP.
        For example, the pre-object-oriented pattern for global functions 
        overriding. In such case the analyzer cannot determine that the unused 
        parameter is in fact a part of an interface. Note that such function 
        could omit the unused parameter and everything would work the same, 
        therefore this may or may not be considered a false positive.
    \item[] \textit{Amendable false positive} -- false positives 
        that are reported, although the algorithm the analyzer 
        is using should not report them. Those can indicate errors 
        in the implementation of the analysis.
    \item[] \textit{Built-in documentation errors} -- false positives 
        due to the inaccuracy of the documentation of built-in 
        functions and classes that was used in the experiment.
\end{itemize}

\subsection{Summary}

The following table provides a summary of the problems found. 
There is a table that lists concrete problems found PHPUnit 
available in \hyperref[phpunittable]{Appendix A}.

\newcommand{\subcat}[1]{\hspace{0.5cm}\small{\textit{#1}}} 
\newcommand{\reldefret}{\subcat{default return value}}

\newcommand{\sumh}[1]{\textbf{#1}}
%\newcommand{\sumh}[1]{\begin{turn}{60}#1\end{turn}}

\begin{center}
    \begin{tabular}{| p{5cm} | r | r | r | r | r |}
    \hline
    \sumh{Category}         &   \sumh{PHPUnit}      &   \sumh{Nette}    & \sumh{Zebra\_Image}    &   \sumh{total}   \\ \hline
    Style                   &   6                   &   0               & 1                 &   7       \\ \hline
    \reldefret              &   2                   &   0               & 0                 &   2       \\ \hline        
    Documentation           &   10                  &   1               & 0                 &   11      \\ \hline    
    \subcat{missing false}  &   3                   &   0              & 0                  &   3       \\ \hline
    Actual Error            &   1                   &   0              & 0                  &   1      \\ \hline    
    False positive          &   8                   &   0              & 0                  &   8      \\ \hline    
   \subcat{unused arguments}&   1                   &   0              & 0                  &   1      \\ \hline        
    \subcat{amendable}      &   4                   &   0              & 0                  &   4      \\ \hline            
 \subcat{built-in doc error}&   3                   &   0              & 0                  &   3      \\ \hline
    \textbf{Total} 
    (excl. false positives) &17                   &   1              & 1            &   19      \\ \hline
    \end{tabular}
\end{center}



\subsection{Selected Problems}

\subsubsection*{Actual Error When Handling \code{DOMElements}}

The error is related to the following code (shortened).

%pygmentize_begin php
% function assertEqualXMLStructure(
%   DOMElement $expectedElement/*, ...*/) {
%   ///...
%   PHPUnit_Util_XML::removeCharacterDataNodes($expectedElement);
%   PHPUnit_Util_XML::removeCharacterDataNodes($actualElement);
%   //...
%   for ($i = 0; $i < $expectedElement->childNodes->length; $i++) {
%       self::assertEqualXMLStructure(
%           $expectedElement->childNodes->item($i) /*<<< error */
%           /*...*/);
% }
%pygmentize_end

The method \code{assertEqualXMLStructure} accepts only instances 
of \code{DOMElement}, but it invokes itself recursively with first 
argument of type \code{DOMNode}. Because according to the 
PHP documentation the value of the \code{childNodes} property 
of interface \code{DOMNode} is an instance of \code{DOMNodeList} 
and the method \code{item(integer)} of \code{DOMNodeList} 
returns \code{DOMNode}, it is a type mismatch error as \code{DOMNode} 
is not subtype of \code{DOMElement}.

In the PHP implementation of DOM model, the only implementations of 
\code{DOMNode} either inherit from \code{DOMElement} or 
implement \code{DOMCharacterData}, and those are removed 
from the \code{childNodes} collection by \code{removeCharacterDataNodes}. 
Therefore, in most cases, this code behaves as expected. 

However, the \code{DOMNode} interface can be implemented by any user 
defined class, which does not have to inherit from 
\code{DOMElement}, and if an instance of such class was present 
in the \code{childNodes} collection, the code would cause an 
exception when trying to invoke \code{assertEqualXMLStructure} 
with an argument of wrong type.

Note that if method \code{removeCharacterDataNodes} removed 
all the child nodes that are not instances of \code{DOMElement}, 
the code would be correct, but the error would still be reported, 
therefore it would be false positive.

\section{Performance}

Execution time and memory consumption were measured for real 
world PHP projects of size from thousands to hundreds of thousands 
of lines of code. In the charts, (K)LOC stands for (thousand) 
lines of code. The experiments were conducted on 
Intel Core i7-4600U, 2.70 GHz with 8GB of RAM memory.
Note that we measured not only the analysis 
itself, but the whole process needed to perform 
the analysis including parsing the source code 
by Phalanger.

The execution time was measured using PowerShell 
\code{Measure-Command} command, which is supposed 
to measure wall clock time in a similar way as UNIX 
\code{time} command. The chart in figure \ref{exectime} 
shows mean values from 20 runs preceded by 2 warm up runs, 
which were not counted. 

\begin{figure}[h]  
  \centering
    \includegraphics*[scale=0.5]{graphs/exectime.jpg}  
    \caption{Execution time mean values for different sizes of analysed code. \label{exectime}}
\end{figure}      

For measuring the memory consumption, Visual Studio 2012 
profiler was used and the results are shown in figure \ref{memusage}. 
The graph shows total number of megabytes allocated.

\begin{figure}[h]  
  \centering
    \includegraphics*[scale=0.55]{graphs/memusage.jpg}  
    \caption{Memory usage for different sizes of analysed code.\label{memusage}}
\end{figure}      

This experiment suggests that the execution time 
scales very well with the growing number of 
lines of code and memory consumption scales 
reasonably good.


